{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercompressible: optimization 3d\n",
    "\n",
    "This notebook intends to show the optimization process to maximize the absorbed energy in the 3D case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's start by importing the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard library\n",
    "import pickle\n",
    "\n",
    "# third-party\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables: ['ratio_d', 'ratio_pitch', 'ratio_top_diameter', 'coilable', 'sigma_crit', 'energy']\n",
      "X: [[0.004      0.25       0.        ]\n",
      " [0.0385     0.875      0.4       ]\n",
      " [0.05575    0.5625     0.2       ]\n",
      " ...\n",
      " [0.06037836 1.08930969 0.58618164]\n",
      " [0.04312836 0.77680969 0.38618164]\n",
      " [0.00862836 1.40180969 0.78618164]]\n",
      "X shape: (10000, 3)\n",
      "y: [2.79529996e-04            nan 1.42853201e+01 ...            nan\n",
      "            nan            nan]\n",
      "y shape: (10000,)\n",
      "y_class: [1. 0. 2. ... 0. 2. 0.]\n",
      "y_class shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# get pandas frame\n",
    "filename = 'DoE_results.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "points = data['points']\n",
    "print('variables:', [col for col in points.columns])\n",
    "\n",
    "# get number of inputs\n",
    "n_inputs = len(points.columns) - 3\n",
    "\n",
    "# get X data\n",
    "X = points.iloc[:,range(n_inputs)].values\n",
    "X_full = points.iloc[:,range(n_inputs)].values\n",
    "\n",
    "# get energy data\n",
    "var_name = 'energy'\n",
    "y = points.loc[:, var_name].values\n",
    "\n",
    "# get coilable data\n",
    "class_name = 'coilable'\n",
    "y_class = points.loc[:, class_name].values\n",
    "\n",
    "print('X:', X)\n",
    "print('X shape:', np.shape(X))\n",
    "print('y:', y)\n",
    "print('y shape:', np.shape(y))\n",
    "print('y_class:', y_class)\n",
    "print('y_class shape:', np.shape(y_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables ```X``` and ```y``` contain all the data. Nevertheless, there's ```NaN``` values that cannot be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 3174\n",
      "Class 1: 2013\n",
      "Class 2: 4813\n"
     ]
    }
   ],
   "source": [
    "for yy in np.unique(y_class):\n",
    "    print('Class %i: %i' % (int(yy), np.sum(y_class==yy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[0.004      0.25       0.        ]\n",
      " [0.05575    0.5625     0.2       ]\n",
      " [0.0686875  0.328125   0.55      ]\n",
      " ...\n",
      " [0.06900336 0.30805969 0.68618164]\n",
      " [0.03450336 0.93305969 0.28618164]\n",
      " [0.02587836 0.46430969 0.18618164]]\n",
      "X shape: (5264, 3)\n",
      "y: [2.79529996e-04 1.42853201e+01 3.99711660e+01 ... 5.35333775e+01\n",
      " 2.35352031e+00 6.15239445e-01]\n",
      "y shape: (5264,)\n",
      "y_class: [1. 0. 2. ... 0. 2. 0.]\n",
      "y_class shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# missing indices\n",
    "indices = pd.notnull(points.loc[:, var_name]).values\n",
    "\n",
    "# get matching energy and coiling data\n",
    "y = points.loc[indices, var_name].values\n",
    "# y_class = points.loc[indices, class_name].values\n",
    "\n",
    "# get X data\n",
    "X = points.iloc[indices,range(n_inputs)].values\n",
    "\n",
    "print('X:', X)\n",
    "print('X shape:', np.shape(X))\n",
    "print('y:', y)\n",
    "print('y shape:', np.shape(y))\n",
    "print('y_class:', y_class)\n",
    "print('y_class shape:', np.shape(y_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_cleaning(X, y, n_std_cleaning):\n",
    "    \n",
    "    # compute threshold\n",
    "    y_mean, y_std = np.mean(y), np.std(y)\n",
    "    y_thresh = y_mean + n_std_cleaning * y_std\n",
    "\n",
    "    # indices\n",
    "    print(y_thresh)\n",
    "    indices = np.where(y < y_thresh)\n",
    "    n_dismissed_points = len(y) - len(indices[0])\n",
    "    print('Dismissed points:', n_dismissed_points)\n",
    "\n",
    "    # X and y\n",
    "    y = y[indices]\n",
    "    X = X[indices]\n",
    "    print(np.shape(y))\n",
    "    print(np.shape(X))\n",
    "\n",
    "    return X, y, n_dismissed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251.41209785647746\n",
      "Dismissed points: 6\n",
      "(5258,)\n",
      "(5258, 3)\n",
      "78.83845527943124\n",
      "Dismissed points: 7\n",
      "(5251,)\n",
      "(5251, 3)\n",
      "76.83459344264611\n",
      "Dismissed points: 0\n",
      "(5251,)\n",
      "(5251, 3)\n"
     ]
    }
   ],
   "source": [
    "n_std_cleaning = 5  # dismiss points that fall outside this range\n",
    "\n",
    "n_dismissed_points = 1\n",
    "while n_dismissed_points > 0:\n",
    "    X, y, n_dismissed_points = perform_cleaning(X, y, n_std_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to create and evaluate the regression and classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_gp_regression(X_train, y_train, kernel):\n",
    "    \n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=kernel, alpha=0.1**2, \n",
    "                                   n_restarts_optimizer=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size):\n",
    "    \n",
    "    # split data\n",
    "    test_size = 1 - train_size\n",
    "    indices = range(len(y))\n",
    "    X_train = X[indices[:-int(round(len(indices) * test_size))]]\n",
    "    X_test = X[indices[-int(round(len(indices) * test_size)):]]\n",
    "    y_train = y[indices[:-int(round(len(indices) * test_size))]]\n",
    "    y_test = y[indices[-int(round(len(indices) * test_size)):]]\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_mean_test, n_train):\n",
    "    \n",
    "    # predict test\n",
    "    y_mean_pred = model.predict(X_test, return_std=False)\n",
    "\n",
    "    # error metrics\n",
    "    mse = mean_squared_error(y_mean_test, y_mean_pred)\n",
    "    r2 = r2_score(y_mean_test, y_mean_pred)\n",
    "    expl_var = explained_variance_score(y_mean_test, y_mean_pred)\n",
    "    print(\"The mean squared error is %0.3e\" % mse)\n",
    "    print(\"The R2 score is %0.3f\" % r2)\n",
    "    print(\"The explained variance score is %0.3f\" % expl_var)\n",
    "\n",
    "    # plot predicted vs observed\n",
    "    plt.figure()\n",
    "    plt.plot(y_mean_test, y_mean_pred, 'o')\n",
    "    plt.plot([np.min(y_mean_test), np.max(y_mean_test)], [np.min(y_mean_test), np.max(y_mean_test)], 'r-')\n",
    "    plt.title('Posterior kernel: %s\\n$n_{train} = %i$, $R^{2} = %0.3f$, $ MSE = %0.3e$' % (model.kernel_, n_train, r2, mse))\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.xlabel(\"Observed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_clf_model(clf, train_data, test_data, metrics=((accuracy_score, 'Accuracy classification score'),), print_results=True):\n",
    "    \n",
    "    # make predictions\n",
    "    y_train_predicted = clf.predict(train_data[0])\n",
    "    y_test_predicted = clf.predict(test_data[0])\n",
    "    \n",
    "    metric_results = []\n",
    "    for Imetric in range(np.shape(metrics)[0]):\n",
    "        metric = metrics[Imetric][0] # select metric used\n",
    "        metric_results.append([metric(train_data[1], y_train_predicted), metric(test_data[1], y_test_predicted)])\n",
    "        \n",
    "        if print_results:\n",
    "            print(\"Train\", metrics[Imetric][1],\"for ML model:\", metric_results[-1][0])\n",
    "            print(\"Test\", metrics[Imetric][1],\"for ML model:\", metric_results[-1][1])\n",
    "        \n",
    "    return metric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy classification score for ML model: 0.89025\n",
      "Test Accuracy classification score for ML model: 0.8895\n"
     ]
    }
   ],
   "source": [
    "# choose train size\n",
    "train_size = .8\n",
    "(X_train, X_test, y_train, y_test) = split_data(X_full, y_class, train_size)\n",
    "n_train = len(X_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# train\n",
    "clf = SVC(kernel='rbf').fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluate model\n",
    "evaluate_clf_model(clf, (X_train_scaled, y_train), (X_test_scaled, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "xx = [[0.04276196, 0.41448975, 0.69628906], # best in full dataset\n",
    "      [0.03954443, 0.51306152, 0.65351563],  # best in full dataset (N=3000)\n",
    "      [0.0337832, 0.32080078, 0.7578125],  # best in full dataset (N=1000)\n",
    "      [0.03710181, 0.26312256, 0.77441406], # best in the dataset after classification with N=10000\n",
    "      [0.02876318, 0.31774902, 0.72851562], # best in the dataset after classification with N=5000\n",
    "      [0.0337832,  0.32080078, 0.7578125], # best in the dataset after classification with N=3000 and N=1000\n",
    "      [0.04, 0.417, 0.8], # best found after after classification and regression with N=10000\n",
    "      [0.038, 0.32, 0.8], # best found after after classification and regression with N=5000\n",
    "      [0.037, 0.32, 0.8], # best found after after classification and regression with N=3000\n",
    "      [0.037, 0.4, 0.8], # best found after after classification and regression with N=1000\n",
    "      ]\n",
    "yy = clf.predict(scaler.transform(xx))\n",
    "\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose train size\n",
    "train_size = .1\n",
    "(X_train, X_test, y_train, y_test) = split_data(X, y, train_size)\n",
    "n_train = len(X_train)\n",
    "\n",
    "# scale data\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# train and predict\n",
    "kernel = 1.0 * Matern(length_scale=1.0, nu=2.5, length_scale_bounds=(1e-1, 10.0))\n",
    "model = make_gp_regression(X_train_scaled, y_train, kernel)\n",
    "\n",
    "# evaluate model\n",
    "# evaluate_model(model, X_test_scaled, y_test, n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04276196, 0.41448975, 0.69628906]]\n",
      "[2.]\n",
      "[9.94200963]\n"
     ]
    }
   ],
   "source": [
    "xx = [[0.04276196, 0.41448975, 0.69628906]]\n",
    "yy = clf.predict(scaler.transform(xx))\n",
    "yyen = model.predict(scaler.transform(xx))\n",
    "\n",
    "print(xx)\n",
    "print(yy)\n",
    "print(yyen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our classification and regression model ready. We can use these functions to optimize for the absorbed energy while making sure that the coilability is favorable (class 1). We can do this by penalizing the other classes. A similar action can be undertaken when the input point does not fall within the bounds of the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[0.04923749, 0.2852253 , 0.84937979],\n",
      "       [0.04923747, 0.28522648, 0.84937952],\n",
      "       [0.04923735, 0.28523207, 0.84937824],\n",
      "       [0.04923731, 0.28523383, 0.84937783]]), array([-21.87044202, -21.87042946, -21.87037191, -21.87035334]))\n",
      "           fun: -21.870442021652707\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 397\n",
      "           nit: 204\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.04923749, 0.2852253 , 0.84937979])\n",
      "\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "variables = ['ratio_d', 'ratio_pitch', 'ratio_top_diameter']\n",
    "bounds = [data['doe_variables'][name] for name in variables]\n",
    "\n",
    "# print(bounds)\n",
    "# print()\n",
    "\n",
    "# def validitycheck(x):\n",
    "#     res = 0\n",
    "#     for i in range(3):\n",
    "#         a = bounds[i][0] <= x[0][i]\n",
    "#         b = x[0][i] <= bounds[i][1]\n",
    "#         c = clf.predict(scaler.transform(x)) == 1\n",
    "#         res += a + b + c\n",
    "#     if res == 9:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# print(validitycheck([[0.04, 0.417, 0.8]]))\n",
    "# print()\n",
    "\n",
    "def objfun(x):\n",
    "#     penalty = 1e5\n",
    "    x = [list(x)]\n",
    "#     print(x)\n",
    "#     print(model.predict(scaler.transform(x)))\n",
    "#     print(clf.predict(scaler.transform(x)))\n",
    "#     print()\n",
    "    if np.rint(clf.predict(scaler.transform(x))) == 1:\n",
    "        output = -model.predict(scaler.transform(x))\n",
    "    else:\n",
    "        output = model.predict(scaler.transform(x))\n",
    "#         output = penalty\n",
    "#     print(-output)\n",
    "#     print()\n",
    "    return output\n",
    "\n",
    "x0 = [[0.04, 0.417, 0.8]]\n",
    "optval = minimize(objfun, x0=x0, method='Nelder-Mead')\n",
    "\n",
    "print(optval)\n",
    "print()\n",
    "print(clf.predict(scaler.transform([list(optval.x)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
